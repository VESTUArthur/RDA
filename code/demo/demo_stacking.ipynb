{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "from rda_package import rda \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from CosinorPy import file_parser, cosinor, cosinor1\n",
    "import random\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "N_TEST=1000\n",
    "REPLICATES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synt_rhythmic_data(filename,half_rnd=False,n_test=1,n_components=1,noise=0.5,replicates=1):\n",
    "        \"\"\"  \n",
    "        Create test data  (rhythmic)\n",
    "        ...\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        filename : str\n",
    "            name of the output file\n",
    "        half_rnd : bool\n",
    "            make half of the data rhythmic and the other half non-rhythmic\n",
    "        n_test : int\n",
    "            number of line in the dataset\n",
    "        n_components : int\n",
    "            number of components in the cosinor data generator\n",
    "        noise : int\n",
    "            % of gaussian noise added\n",
    "        replicates : int\n",
    "            number of replicate in the dataset\n",
    "        \"\"\"\n",
    "        os.makedirs(f'Out/{filename[:-4]}', exist_ok=True)\n",
    "        if(n_components==1):\n",
    "            df_rhd=file_parser.generate_test_data_group(N=n_test,n_components = n_components, noise=noise, replicates = replicates)\n",
    "        else:\n",
    "           df_rhd=file_parser.generate_test_data_group(N=n_test,n_components = n_components, noise=noise, replicates = replicates, \n",
    "                amplitudes = [1, np.random.random(), np.random.random()], phase = [2*np.pi*np.random.random(), 2*np.pi*np.random.random(), 2*np.pi*np.random.random()])\n",
    "        df_str_col=pd.DataFrame()\n",
    "        for i in range(1,replicates+1):\n",
    "            str_col= 'ZT_'+ df_rhd[\"x\"].astype(int).astype(str) + f'_{i}' \n",
    "            df_str_col=pd.concat([df_str_col,pd.Series(str_col.unique())],ignore_index=True)\n",
    "        df_rhd_res =pd.DataFrame(index=df_rhd.test.unique(),columns=df_str_col.to_numpy().flatten()) \n",
    "        var = 0\n",
    "        for i in range(len(df_rhd_res)):\n",
    "            for col in df_rhd_res:\n",
    "                df_rhd_res[col].iloc[i]= df_rhd.iloc[var].y\n",
    "                var+=1  \n",
    "        df_int_col=pd.DataFrame()\n",
    "        for i in range(1,replicates+1):\n",
    "            int_col=df_rhd[\"x\"].astype(int).astype(str)\n",
    "            df_int_col=pd.concat([df_int_col,pd.Series(int_col.unique())],ignore_index=True)\n",
    "        df_rhd_res.columns=df_int_col.to_numpy().astype(int).flatten()\n",
    "        df_results = df_rhd_res\n",
    "        if(half_rnd==True):\n",
    "            half=n_test//2\n",
    "            df_rnd_res=df_rhd_res.iloc[:half,]\n",
    "            print(df_rnd_res)\n",
    "            df_rhd_res=df_rhd_res.iloc[half:,]\n",
    "            print('---------ok-----------')\n",
    "            print(df_rhd_res)\n",
    "            #df_rnd_res.columns=random.sample(list(df_int_col.to_numpy().astype(int).flatten()), len(df_int_col.to_numpy().flatten()))  \n",
    "            list_col=list(df_int_col.to_numpy().astype(int).flatten())\n",
    "            random.shuffle(list_col) \n",
    "            df_rnd_res.columns=list_col\n",
    "            df_rnd_res = df_rnd_res.sort_index(axis=1)\n",
    "            print(df_rnd_res.columns) \n",
    "            df_results=pd.concat([df_rhd_res,df_rnd_res],ignore_index=True)\n",
    "        print(df_results.columns)          \n",
    "        df_results.to_csv(f\"Out/{filename[:-4]}/{filename[:-4]}.csv\")\n",
    "        return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [3]:\n",
    "    for j in [1,2]:\n",
    "        FILENAME=f\"stack_c{i}_n0{3*j}.csv\"\n",
    "        folder_in = f'Out/{FILENAME[:-4]}/'\n",
    "        NOISE=float(0.3*j)\n",
    "        N_COMPONENTS=int(i)\n",
    "        synt_rhythmic_data(FILENAME,half_rnd=True,n_test=N_TEST,n_components=N_COMPONENTS,noise=NOISE,replicates=REPLICATES)\n",
    "        rda.file_rda(folder_in+FILENAME,metrics=True,half_rnd=True,n_components=N_COMPONENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=3\n",
    "j=3\n",
    "filename=f\"stack_c{i}_n0{3*j}.csv\"\n",
    "qv = pd.read_csv(f\"Out/{filename[:-4]}/qv_{filename[:-4]}.csv\")\n",
    "y = pd.DataFrame([1] * (len(qv)//2), columns=['y'])\n",
    "y = pd.concat([y,pd.DataFrame([0] * (len(qv)//2), columns=['y'])],ignore_index=True)\n",
    "qv['y']=y\n",
    "qv = qv.sample(frac=1).reset_index(drop=True)\n",
    "qv=qv.drop('CycID',axis=1)\n",
    "qv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mcc models evaluation qvalue\n",
    "ncols = 3\n",
    "nrows = 3\n",
    "fig, axes = plt.subplots(ncols = ncols, nrows = nrows, sharey=False)\n",
    "axes = axes.flatten()         \n",
    "fig.set_size_inches(30, 30)\n",
    "sns.set_style(\"white\")\n",
    "flatui = ['#d9d9d9','#bdbdbd','#969696','#737373','#525252','#252525']\n",
    "filenames = []\n",
    "for i in [1,2,3]:\n",
    "    for j in [1,2,3]:\n",
    "        filename = f\"stack_c{i}_n0{3*j}.csv\"\n",
    "        filenames.append(filename)\n",
    "for ax, filename in zip(axes,filenames):\n",
    "            df_metrics = pd.read_csv(f\"Out/{filename[:-4]}/qv_metrics_{filename[:-4]}.csv\")\n",
    "            sns.barplot(data=df_metrics, x='model', y='mcc', ax=ax, ci=68, capsize=.2, palette=flatui) # ci=68 --> standard error!\n",
    "            ax.set_ylabel(f'n_components = {filename[1]}')\n",
    "            ax.set_xlabel(f'noise = 0.{filename[-5]}')\n",
    "plt.suptitle(f\"Matthew's Correlation Coefficient for models evaluation qv\")\n",
    "fig.subplots_adjust(top=0.95)\n",
    "plt.savefig(f\"Out/models_qv_mcc.png\", bbox_inches=\"tight\", facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def plot_result(grid,X_test,y_test):\n",
    "    y_pred = grid.predict(X_test)\n",
    "    cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "    group_counts = ['{0:0.0f}'.format(value) for value in cf_matrix.flatten()]\n",
    "    group_percentages = ['{0:.2%}'.format(value) for value in cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "    labels = [f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "    sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')\n",
    "    print('Score : ',grid.score(X_test,y_test),'\\n',grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(qv.drop('y',axis=1),qv['y'], test_size=0.5)\n",
    "print(X_train,y_train)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "clf = DecisionTreeClassifier()\n",
    "params = {\n",
    "           'max_depth': [3],\n",
    "           'min_samples_leaf': [1,10,30,70],\n",
    "           'criterion':['gini','entropy']\n",
    "    }\n",
    "grid = GridSearchCV(clf,param_grid=params,cv=3)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "#Get the confusion matrix\n",
    "plot_result(grid,X_test,y_test)\n",
    "fig = plt.figure(figsize=(50,50))\n",
    "plot_tree(grid.best_estimator_, feature_names=X_test.columns,  \n",
    "                   class_names=['0','1'],\n",
    "                   filled=True)\n",
    "fig.savefig(\"decistion_tree.png\", facecolor='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "clf = xgb.XGBClassifier(objective='binary:logistic',eval_metric='mlogloss',use_label_encoder=False )\n",
    "params = {\n",
    "           'n_estimators':[250,350],\n",
    "           'max_depth': [10,70,100],\n",
    "           'learning_rate': [0.1,1]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(clf, param_grid=params,verbose=1,return_train_score=True,scoring='f1_micro',cv=3)\n",
    "grid.fit(X_train, y_train)\n",
    "plot_result(grid,X_test,y_test)\n",
    "#Get the confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_metrics= pd.DataFrame()\n",
    "for i in [1,2,3]:\n",
    "    for j in [1,2,3]:\n",
    "        filename=f\"stack_c{i}_n0{3*j}.csv\"\n",
    "        df_tmp = pd.read_csv(f\"Out/{filename[:-4]}/qv_metrics_{filename[:-4]}.csv\")\n",
    "        df_tmp['filename']=filename\n",
    "        df_metrics =pd.concat([df_metrics,df_tmp])\n",
    "df_metrics"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "767c48a64caae0be89fa7f8f777746ad491056046165076895ba67746a6851de"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
